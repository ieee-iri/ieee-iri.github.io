<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>IEEE IRI 2023</title>
  <link href="css/bootstrap.min.css" rel="stylesheet">
  <link rel="stylesheet" href="css/iri.css">
  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
        <script src="//cdn.bootcss.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="//cdn.bootcss.com/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>
  <div id="header"></div>
  <div class="container">
    <div class="row">
      <div class="col-md-9 col-sm-9">
        <div class="row">
          <div class="row">
            <h3>MIPR & IRI Keynote Speakers</h3>
            <div class="col-md-12">
              <h4>Advancing Beyond LLM Limitations Through Adaptive Multi-Modal Multi-Agent Systems</h4>
              <h5>
                <strong>
                  <span>Edward Y. Chang</span>
                  <br>
                  <em>
                    <span>Stanford University</span>
                  </em>
                </strong>
              </h5>
              <div class="row">
                <div class="col-md-12">
                  <div class="row">
                    <div class="col-md-3">
                      <img src="resources/images/Edward_Chang.png" class="img-responsive" alt="Edward Y. Chang">
                    </div>
                    <div class="col-md-9">
                      <p class="text-justify">
                        <strong>Abstract: </strong>
                      <p class="text-justify">
                        Current large-scale Language Models (LLMs) face fundamental limitations in complex planning
                        tasks despite their increasing scale. These models exhibit four critical constraints: maximum
                        likelihood bias that favors common but suboptimal solutions, inability to validate their own
                        outputs, attention mechanisms that lose track of long-range dependencies, and compounding errors
                        in multi-step reasoning chains. This talk presents a novel solution: an adaptive multi-agent
                        framework where specialized agents process and integrate multiple modalities of information—from
                        text and numerical data to visual and temporal signals. Through a distributed architecture with
                        hierarchical validation, our system enables each agent to focus on specific tasks and modalities
                        while maintaining global consistency across all information types. We'll demonstrate this
                        approach through real-world planning scenarios, showing how architectural innovation in
                        multi-modal, multi-agent systems, rather than continued scaling of single-modality models,
                        offers a more promising direction for advancing AI capabilities.
                      <p class="text-justify">
                        <strong>Bio:</strong>
                        Edward Y. Chang is an adjunct professor of computer science at Stanford University since 2019.
                        He has been a pioneer in data-driven large-scale distributed learning, AI-driven healthcare, and
                        advancing LLMs beyond their limitations to improve reasoning, planning, and decision-making.

                        Previously, Chang served as President of HTC Research & Healthcare(2012-2020), where he led
                        AI-powered precision medicine initiatives, including mobile health monitoring and disease
                        prediction. From 2006 to 2012, he was Director of Research at Google, where he spearheaded
                        advancements in parallel machine learning infrastructure, Google Q&A, and social media
                        analytics.

                        In academia, he was a tenured professor at UC Santa Barbara (1999-2006), an adjunct professor at
                        HKUST (2012-2015), and a visiting professor at UC Berkeley (2017-2020). He was recognized as a
                        Fellow of ACM and IEEE for his contributions to scalable machine learning and AI-driven
                        healthcare and was awarded the XPRIZE Tricorder $1M prize for his work on AI-powered medical
                        IoTs.

                        Chang holds an M.S. in Computer Science and a Ph.D. in Electrical Engineering, both from
                        Stanford University.
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <div class="col-md-12">
              <h4>The Future of Discovery Assistance</h4>
              <h5>
                <strong>
                  <span>Ed H. Chi</span>
                  <br>
                  <em>
                    <span>Google DeepMind</span>
                  </em>
                </strong>
              </h5>
              <div class="row">
                <div class="col-md-12">
                  <div class="row">
                    <div class="col-md-3">
                      <img src="resources/images/Ed_Chi.png" class="img-responsive" alt="Ed H. Chi">
                    </div>
                    <div class="col-md-9">
                      <p class="text-justify">
                        <strong>Abstract: </strong>
                      <p class="text-justify">
                        Our field has shifted from traditional machine learning techniques that are mostly based on
                        pattern recognition to sequence-to-sequence models. The future of universal personal assistance
                        for discovery and learning is upon us. How will multimodality image, video, and audio
                        understanding, and reasoning abilities of large foundation models change how we build these
                        systems? I will shed some initial light on this topic by discussing some trends: First, the move
                        to a single multimodal large model with reasoning abilities; Second, the fundamental research on
                        personalization and user alignment; Third, the combination of System 1 and System 2 cognitive
                        abilities into a single universal assistant.
                      <p class="text-justify">
                        <strong>Bio:</strong>
                        Ed H. Chi is VP of Research at Google DeepMind, leading machine learning research teams working
                        on large language models (from LaMDA leading to launching Bard/Gemini), and neural
                        recommendation agents. With 39 patents and ~200 research articles, he is also known for research
                        on user behavior in web and social media. As the Research Platform Lead, he helped launched
                        Bard/Gemini, a conversational AI experiment. His research also delivered significant
                        improvements for YouTube, News, Ads, Google Play Store at Google with >930 product landings and
                        ~$9B in annual revenue since 2013.

                        Prior to Google, he was Area Manager and Principal Scientist at Xerox Palo Alto Research
                        Center's Augmented Social Cognition Group in researching how social computing systems help
                        groups of people to remember, think and reason. Ed earned his 3 degrees (B.S., M.S., and Ph.D.)
                        in 6.5 years from University of Minnesota. Inducted as an ACM Fellow and into the CHI Academy,
                        he also received a 20-year Test of Time award for research in information visualization. He has
                        been featured and quoted in the press, including the Economist, Time Magazine, LA Times, and the
                        Associated Press. An avid golfer, swimmer, photographer and snowboarder in his spare time, he
                        also has a blackbelt in Taekwondo.
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <div class="col-md-12">
              <h4>LLMs (for code) sometimes make mistakes. When should I trust them?</h4>
              <h5>
                <strong>
                  <span>Prem Devanbu</span>
                  <br>
                  <em>
                    <span>University of California, Davis</span>
                  </em>
                </strong>
              </h5>
              <div class="row">
                <div class="col-md-12">
                  <div class="row">
                    <div class="col-md-3">
                      <img src="resources/images/Prem_Devanbu.png" class="img-responsive" alt="Prem Devanbu">
                    </div>
                    <div class="col-md-9">
                      <p class="text-justify">
                        <strong>Abstract: </strong>
                      <p class="text-justify">
                        At UC Davis, we first introduced the possibility of using Language Models for code, back in
                        2012; since then, the idea has matured, and now LLMs are widely used for software-engineering
                        related tasks. However, LLMs make a lot of mistakes when generating software-related artifacts;
                        so what should a developer do with LLM output? We discuss some empirical findings, and some
                        recent work on trying to get LLMs to provide a reliable indication of how confident they are in
                        their output. If this indication is reliable, perhaps we can decide on a more rational way to
                        use LLM outputs, balancing productivity gains with quality risk. We offer confidence-reliability
                        (calibration) results for 2 tasks, code completion and code summarization, and speculate on what
                        should happen next.

                        Joint work with Toufique Ahmed, David Gros, Claudio Spiess and Yuvraj Virk (all students at UC
                        Davis), Michael Pradel at Uni. Stuttgart, Amin Alipour at U. Houston and Susmit Jha at SRI; the
                        talk discussed very recent work, including a new paper to be published ICSE 2025.
                      <p class="text-justify">
                        <strong>Bio:</strong>
                        Prem Devanbu holds a B.Tech from IIT Madras, and a Ph.D from Rutgers University. After decades
                        at Bell Labs in New Jersey, he joined UC Davis where he conducts research in software
                        engineering. In 2021, he was awarded the ACM SIGSOFT Outstanding Research Award, and in 2022 the
                        Alexander von Humboldt Research Award, and in 2024 the IEEE Computer Society Harlan Mills Award,
                        all mostly for the ICSE 2012 "Naturalness of Software" paper from UC Davis, which showed that
                        Language Models are effective for Code. He serves as co-chair of the Research Articles track of
                        the Communications of the ACM, and is an ACM Fellow.
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <div class="col-md-12">
              <h4>TBD</h4>
              <h5>
                <strong>
                  <span>Alexei (Alyosha) Efros</span>
                  <br>
                  <em>
                    <span>University of California, Berkeley</span>
                  </em>
                </strong>
              </h5>
              <div class="row">
                <div class="col-md-12">
                  <div class="row">
                    <div class="col-md-3">
                      <!-- <img src="resources/images/Prem_Devanbu.png" class="img-responsive" alt="Prem Devanbu"> -->
                    </div>
                    <div class="col-md-9">
                      <p class="text-justify">
                        <strong>Abstract: </strong>
                      <p class="text-justify">
                        TBD
                      <p class="text-justify">
                        <strong>Bio:</strong>
                        TBD
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <div class="col-md-12">
              <h4>Can Computers Create Art?</h4>
              <h5>
                <strong>
                  <span>Aaron Hertzmann</span>
                  <br>
                  <em>
                    <span>Adobe Research</span>
                  </em>
                </strong>
              </h5>
              <div class="row">
                <div class="col-md-12">
                  <div class="row">
                    <div class="col-md-3">
                      <img src="resources/images/Aaron_Hertzmann.png" class="img-responsive" alt="Aaron Hertzmann">
                    </div>
                    <div class="col-md-9">
                      <p class="text-justify">
                        <strong>Abstract: </strong>
                      <p class="text-justify">
                        Can AI algorithms make art, and be considered artists? Within the past decade, the growth of new
                        neural network algorithms has enabled exciting new art forms with considerable public interest.
                        These tools raise recurring questions about their status as creators and their effect on the
                        arts. In this talk, I will discuss how these developments parallel the development of previous
                        artistic technologies, like oil paint, photography, and traditional computer graphics, with many
                        useful analogies between past and current developments. I argue that art is a social phenomenon,
                        that “AI” algorithms will not have human-level intelligence in the foreseeable future, and thus
                        it is extremely unlikely that we will ever consider algorithms to be artists. However they, like
                        past art technologies, will change the way we make and understand art.
                      <p class="text-justify">
                        <strong>Bio:</strong>
                        Aaron Hertzmann is a Principal Scientist at Adobe Research, and Affiliate Faculty at University
                        of Washington. He received a bachelor's degree in Computer Science and Art at Rice University
                        and a PhD degree in Computer Science from New York University. He was previously a Professor of
                        Computer Science at the University of Toronto for ten years. He has published over 120 papers in
                        computer graphics, several subfields of AI, and in the science of art. He is an IEEE Fellow, an
                        ACM Fellow, and winner of the 2024 SIGGRAPH Computer Graphics Achievement Award.
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <div class="col-md-12">
              <h4>Trustworthy Artificial Intelligence for Securing Transportation Systems</h4>
              <h5>
                <strong>
                  <span>Bhavani Thuraisingham</span>
                  <br>
                  <em>
                    <span>University of Texas, Dallas</span>
                  </em>
                </strong>
              </h5>
              <div class="row">
                <div class="col-md-12">
                  <div class="row">
                    <div class="col-md-3">
                      <img src="resources/images/Bhavani_Thuraisingham.png" class="img-responsive"
                        alt="Bhavani Thuraisingham">
                    </div>
                    <div class="col-md-9">
                      <p class="text-justify">
                        <strong>Abstract: </strong>
                      <p class="text-justify">
                        Artificial Intelligence (AI) techniques ae being applied to numerous applications from
                        Healthcare to Cyber Security to Finance. For example, Machine Learning (ML) algorithms are being
                        applied to solve security problems such as malware analysis and insider threat detection.
                        However, there are many challenges in applying ML algorithms for various applications. For
                        example, (i) the ML algorithms may violate the privacy of individuals. This is because we can
                        gather massive amounts of data and apply ML algorithms on the data to extract highly sensitive
                        information. (ii) ML algorithms may show bias and be unfair to various segments of the
                        population. (iii) ML algorithms themselves may be attacked possibly resulting in catastrophic
                        errors including in cyber physical systems such as transportation systems.

                        In this presentation, we discuss our research we are conducting as part of the USDOT National
                        University Technology Center <b>TraCR</b> (<b>Tra</b>nsportation <b>C</b>ybersecurity and
                        <b>R</b>esiliency) led by Clemson University. In particular, we describe (i) the application of
                        federated machine learning techniques for detecting attacks in transportation systems; (ii)
                        publishing synthetic transportation data sets that preserves privacy, (iii) fairness algorithms
                        for transportation systems, and (iv) examining how GenAI systems are being integrated with
                        transportation systems to provide security. We also discuss aspects of securing multimedia and
                        systems, and (iv) examining how GenAI systems are being integrated with transportation systems
                        to provide security. We also discuss aspects of securing multimedia and multimodal data for
                        transportation systems. Finally we discuss resiliency issues with respect to transportation
                        systems where such systems and applications must continue to operate in the midst of attacks and
                        failures
                      <p class="text-justify">
                        <strong>Bio:</strong>
                        Dr. Bhavani Thuraisingham is the Founders Chair Professor of Computer Science and the Founding
                        Executive Director of the Cyber Security Research and Education Institute at the University of
                        Texas at Dallas (UTD). She is an elected Fellow of the ACM, IEEE, the AAAS, and the NAI. Her
                        research interests are integrating cyber security and artificial intelligence/data science
                        including as they relate to the cloud, social media, and Transportation Systems. She has
                        received several technical, education and leadership awards including the IEEE CS 1997 Edward J.
                        McCluskey Technical Achievement Award, the IEEE CS 2023 Taylor L. Booth Education Award, ACM
                        SIGSAC 2010 Outstanding Contributions Award, the IEEE Comsoc Communications and Information
                        Security 2019 Technical Recognition Award, the IEEE CS Services Computing 2017 Research
                        Innovation Award, the ACM CODASPY 2017 Lasting Research Award, and the ACM SACMAT 10 Year Test
                        of Time Awards for 2018 and 2019 (for papers published in 2008 and 2009). Her 44+ year career
                        includes industry (Honeywell), federal research laboratory (MITRE), US government (NSF) and US
                        Academia. Her work has resulted in 140+ journal articles, 300+ conference papers, 200+ keynote
                        and featured addresses, seven US patents, sixteen books, and over 120 panel presentations
                        including at Fortune Media, Lloyds of London Insurance, Dell Technologies World, United Nations,
                        and the White House Office of Science and Technology Policy. She has also written opinion
                        columns for popular venues such as the New York Times, Inc. Magazine, Womensday.com and the
                        Legal 500, She received her PhD from the University of Wales, Swansea, UK, and the prestigious
                        earned higher doctorate (D. Eng) from the University of Bristol, UK. She also has a Certificate
                        in Public Policy Analysis from the London School of Economics and Political Science. She has
                        been featured in the book by the ACM in 2024 titled: “Rendering History: The Women of ACM-W” as
                        one of the 30+ “Women that Changed the Face of World Wide Computing Forever.”
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <!--start the next keynote segment here-->

          </div>
        </div>
      </div>

      <div class="col-md-3 col-sm-3">
        <div id="right-side"></div>
      </div>
    </div>
  </div>


  <div id="footer"></div>

  <script src="js/jquery-1.11.3.min.js"></script>
  <script src="js/bootstrap.min.js"></script>
  <script>
    $("#header").load("header.html");
    $("#footer").load("footer.html");
    $("#right-side").load("side.html");
  </script>
</body>

</html>